{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Usage Example of the HAL Project Group\n",
    "## Prerequisite: \n",
    "- Importing required libraries, \n",
    "- Setting system path\n",
    "- Importing HAL project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.getcwd() + \"/hal_pm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hal_pm import *\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.) & 2.): Etablishing connection to Rest-API and requesting the data\n",
    "The load_data function takes the coordinates (latitude and logitude, start and end point each) as well as a start date in `datetime` format and number of delta hours as input values. \n",
    "In first place, PM2.5 and PM10 `pandas` data frames are created seperetally. Meanwhile it creates the unique identifier column *measurement_id*, which is a combination of *sensor_id* and *time* columns in each data frame. By the unique identifier, PM2.5 and PM10 data frames are merged into a large one (since a single sensor always measures PM10 and PM2.5 values). After reordering the columns, the large data frame containing all *measurements*, *dates*, *coordinates* and *sensor_id*s is outputted to the user.\n",
    "\n",
    "#### Place and time of measurements:\n",
    "As a group, we decided to take a look at Stuttgart's fine particulate pollution in our example. This is reasoned on in the fact, that Stuttgart were famous for its ban on diesel-powered vehicles in an early stage compared to the rest of germany. Due to the fact, that one hour already contains 20134 observations, we couldn't take a longer time period into account (otherwise, loading data would take too much time). Therefore *start_date* is chosen without purpose as well. However, by only defining the datetime as *YYYY, MM, DD*, the measurements start on midnight 2018-06-01 and end on 1:00 am 2018-06-01."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "start_date = datetime.datetime(2018, 6, 1)\n",
    "pmdata = Load_Data.load_data(lat_start = 48.5, lat_end = 49, long_start = 9, long_end = 9.3, start_datetime = start_date, delta_hours = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>measurement_PM10</th>\n",
       "      <th>measurement_PM2.5</th>\n",
       "      <th>time</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>sensor_id</th>\n",
       "      <th>measurement_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-06-01T00:00:01Z</td>\n",
       "      <td>48.798</td>\n",
       "      <td>9.070</td>\n",
       "      <td>11264</td>\n",
       "      <td>11264_2018-06-01T00:00:01Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.67</td>\n",
       "      <td>1.27</td>\n",
       "      <td>2018-06-01T00:00:01Z</td>\n",
       "      <td>48.949</td>\n",
       "      <td>9.098</td>\n",
       "      <td>122</td>\n",
       "      <td>122_2018-06-01T00:00:01Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.60</td>\n",
       "      <td>1.77</td>\n",
       "      <td>2018-06-01T00:00:01Z</td>\n",
       "      <td>48.765</td>\n",
       "      <td>9.147</td>\n",
       "      <td>4383</td>\n",
       "      <td>4383_2018-06-01T00:00:01Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12.35</td>\n",
       "      <td>2.42</td>\n",
       "      <td>2018-06-01T00:00:01Z</td>\n",
       "      <td>48.779</td>\n",
       "      <td>9.034</td>\n",
       "      <td>181</td>\n",
       "      <td>181_2018-06-01T00:00:01Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-06-01T00:00:01Z</td>\n",
       "      <td>48.779</td>\n",
       "      <td>9.034</td>\n",
       "      <td>182</td>\n",
       "      <td>182_2018-06-01T00:00:01Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20129</th>\n",
       "      <td>3.90</td>\n",
       "      <td>1.33</td>\n",
       "      <td>2018-06-01T00:59:59Z</td>\n",
       "      <td>48.759</td>\n",
       "      <td>9.162</td>\n",
       "      <td>309</td>\n",
       "      <td>309_2018-06-01T00:59:59Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20130</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-06-01T00:59:59Z</td>\n",
       "      <td>48.536</td>\n",
       "      <td>9.274</td>\n",
       "      <td>202</td>\n",
       "      <td>202_2018-06-01T00:59:59Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20131</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-06-01T00:59:59Z</td>\n",
       "      <td>48.692</td>\n",
       "      <td>9.148</td>\n",
       "      <td>2493</td>\n",
       "      <td>2493_2018-06-01T00:59:59Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20132</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-06-01T00:59:59Z</td>\n",
       "      <td>48.799</td>\n",
       "      <td>9.224</td>\n",
       "      <td>5356</td>\n",
       "      <td>5356_2018-06-01T00:59:59Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20133</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-06-01T00:59:59Z</td>\n",
       "      <td>48.759</td>\n",
       "      <td>9.162</td>\n",
       "      <td>310</td>\n",
       "      <td>310_2018-06-01T00:59:59Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20134 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       measurement_PM10  measurement_PM2.5                  time     lat  \\\n",
       "0                   NaN                NaN  2018-06-01T00:00:01Z  48.798   \n",
       "1                  2.67               1.27  2018-06-01T00:00:01Z  48.949   \n",
       "2                  8.60               1.77  2018-06-01T00:00:01Z  48.765   \n",
       "3                 12.35               2.42  2018-06-01T00:00:01Z  48.779   \n",
       "4                   NaN                NaN  2018-06-01T00:00:01Z  48.779   \n",
       "...                 ...                ...                   ...     ...   \n",
       "20129              3.90               1.33  2018-06-01T00:59:59Z  48.759   \n",
       "20130               NaN                NaN  2018-06-01T00:59:59Z  48.536   \n",
       "20131               NaN                NaN  2018-06-01T00:59:59Z  48.692   \n",
       "20132               NaN                NaN  2018-06-01T00:59:59Z  48.799   \n",
       "20133               NaN                NaN  2018-06-01T00:59:59Z  48.759   \n",
       "\n",
       "         lon sensor_id              measurement_id  \n",
       "0      9.070     11264  11264_2018-06-01T00:00:01Z  \n",
       "1      9.098       122    122_2018-06-01T00:00:01Z  \n",
       "2      9.147      4383   4383_2018-06-01T00:00:01Z  \n",
       "3      9.034       181    181_2018-06-01T00:00:01Z  \n",
       "4      9.034       182    182_2018-06-01T00:00:01Z  \n",
       "...      ...       ...                         ...  \n",
       "20129  9.162       309    309_2018-06-01T00:59:59Z  \n",
       "20130  9.274       202    202_2018-06-01T00:59:59Z  \n",
       "20131  9.148      2493   2493_2018-06-01T00:59:59Z  \n",
       "20132  9.224      5356   5356_2018-06-01T00:59:59Z  \n",
       "20133  9.162       310    310_2018-06-01T00:59:59Z  \n",
       "\n",
       "[20134 rows x 7 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pmdata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.) Data Filtering\n",
    "These functions roughly clean the data. That is, they eliminate observations with missing values as well as outlier observations following a user-specified option. As soon as either a PM10 or a PM2.5 measurement is missing or identified as an outlier, the function removes the entire observation. We chose this approach since we aim at calculating correlations between PM10 and PM2.5 measurements, thus we need valid data for both. Moreover, the amount of data is vast and assuming that outliers as well as missing values are random, we can remove the respective observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9590 observations with missing values were removed from the data frame\n",
      "56 outlier observations were deleted\n",
      "       measurement_PM10  measurement_PM2.5                  time     lat  \\\n",
      "1                  2.67               1.27  2018-06-01T00:00:01Z  48.949   \n",
      "2                  8.60               1.77  2018-06-01T00:00:01Z  48.765   \n",
      "3                 12.35               2.42  2018-06-01T00:00:01Z  48.779   \n",
      "5                  1.10               1.10  2018-06-01T00:00:01Z  48.791   \n",
      "8                  5.12               2.78  2018-06-01T00:00:02Z  48.757   \n",
      "...                 ...                ...                   ...     ...   \n",
      "20119              5.10               1.15  2018-06-01T00:59:58Z  48.942   \n",
      "20121              1.80               1.40  2018-06-01T00:59:58Z  48.870   \n",
      "20124              3.23               1.80  2018-06-01T00:59:59Z  48.784   \n",
      "20126             23.43              18.10  2018-06-01T00:59:59Z  48.516   \n",
      "20129              3.90               1.33  2018-06-01T00:59:59Z  48.759   \n",
      "\n",
      "         lon sensor_id              measurement_id  \n",
      "1      9.098       122    122_2018-06-01T00:00:01Z  \n",
      "2      9.147      4383   4383_2018-06-01T00:00:01Z  \n",
      "3      9.034       181    181_2018-06-01T00:00:01Z  \n",
      "5      9.178      7651   7651_2018-06-01T00:00:01Z  \n",
      "8      9.256       950    950_2018-06-01T00:00:02Z  \n",
      "...      ...       ...                         ...  \n",
      "20119  9.256       434    434_2018-06-01T00:59:58Z  \n",
      "20121  9.185      7673   7673_2018-06-01T00:59:58Z  \n",
      "20124  9.197     11933  11933_2018-06-01T00:59:59Z  \n",
      "20126  9.063       499    499_2018-06-01T00:59:59Z  \n",
      "20129  9.162       309    309_2018-06-01T00:59:59Z  \n",
      "\n",
      "[10488 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# Clear Data\n",
    "pmdata = Filter_Data.remove_missing(pmdata)\n",
    "pmdata = Filter_Data.remove_outliers(pmdata ,method = \"Z-score\")\n",
    "print(pmdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.) Descriptive Statistics\n",
    "These functions provide high-level descriptive statistics. `get_max` outputs a pandas dataframe containining the maximium oberservations for PM10 and Pm2.5 measurements. Moreover, the function provides an option to ouput a map with the location of the maxima. `plot_mean_pm` on the other hand outputs a plot with the mean PM10 and PM2.5 concentration over time in the study area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxi, maxi_map = Descriptive_Stats.get_max(pmdata, get_map = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxi_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Descriptive_Stats.plot_mean_pm(pmdata, time_interval = \"5Min\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.) Time histories of fine particulate pollution for the sensors with the highest and lowest mean pollution levels\n",
    "\n",
    "The `plot_average_pol` function evaluates the *sensor_id*s with the lowest and highest average measurement per PM10/PM2.5 seperatelly. In a second steps, it takes the measurements of these sensors and plots them against a timeline. The plot is organized in subplots as following:\n",
    "- **Rows**: PM10 or PM2.5 measurement\n",
    "- **Columns**: sensors with average maximum (Red) or average minumum (Blue)\n",
    "\n",
    "In case one is wondering why the average minimum time plot of PM10 measurment is a horizontal line: probably due to measurment errors, the sensor is measuring the same value all the time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot average polution\n",
    "Time_Plots.plot_average_pol(pmdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_PM10 = min(pmdata.groupby(\"sensor_id\").mean()['measurement_PM10'])\n",
    "min_PM10_id = pmdata.groupby(\"sensor_id\").mean()[pmdata.groupby(\"sensor_id\").mean()['measurement_PM10'] == min_PM10].index[0]\n",
    "df_min_PM10 = pmdata.loc[pmdata['sensor_id'] == min_PM10_id]\n",
    "print(\"Minimal Average PM10 Measurement:\")\n",
    "df_min_PM10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.)  Mapping the data\n",
    "The `map_data` function takes a `pandas` dataframe with PM10 andPM2.5 measurements as input an returns respective interactive maps which indicate the concentration of PM10 andPM2.5 in the study area. The time slider may be used to see concentration changes over time. Along the pandas dataframe, the user should provide a geojson file, which contains the geometries to which he or she would like to aggregate the data to. With the geojson file that we provide in this usage example, we can cover any coordinates in Germany. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "DriverError",
     "evalue": "package/mapping_data/plz_ger.geojson: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCPLE_OpenFailedError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32mfiona/_shim.pyx\u001b[0m in \u001b[0;36mfiona._shim.gdal_open_vector\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mfiona/_err.pyx\u001b[0m in \u001b[0;36mfiona._err.exc_wrap_pointer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mCPLE_OpenFailedError\u001b[0m: package/mapping_data/plz_ger.geojson: No such file or directory",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mDriverError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-98e8265cfc20>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m pm10_map = Map.map_data(df = pmdata, geo_boundaries = 'package/mapping_data/plz_ger.geojson',\n\u001b[0m\u001b[1;32m      2\u001b[0m                         measurement_type = \"measurement_PM10\", lat = 'lat', lon = 'lon', time_interval = \"5Min\")\n\u001b[1;32m      3\u001b[0m pm25_map = Map.map_data(df = pmdata, geo_boundaries = 'package/mapping_data/plz_ger.geojson',\n\u001b[1;32m      4\u001b[0m                         measurement_type = \"measurement_PM2.5\", lat = 'lat', lon = 'lon', time_interval = \"5Min\")\n",
      "\u001b[0;32m~/Documents/AngSt/Semester_2/Python/HAL/hal_pm/hal_pm/Map.py\u001b[0m in \u001b[0;36mmap_data\u001b[0;34m(df, geo_boundaries, lat, lon, measurement_type, time_interval)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;31m# first load the geo boundaries and create a geopandas dataframe out of df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m     \u001b[0mplz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgeo_boundaries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m     \u001b[0mgeo_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGeoDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgeometry\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoints_from_xy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"lon\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"lat\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4326\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/geopandas/io/file.py\u001b[0m in \u001b[0;36m_read_file\u001b[0;34m(filename, bbox, mask, rows, **kwargs)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mfiona_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_bytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0;31m# In a future Fiona release the crs attribute of features will\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/fiona/env.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    406\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlocal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_env\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 408\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    409\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/fiona/__init__.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, driver, schema, crs, encoding, layer, vfs, enabled_drivers, crs_wkt, **kwargs)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m             c = Collection(path, mode, driver=driver, encoding=encoding,\n\u001b[0m\u001b[1;32m    257\u001b[0m                            layer=layer, enabled_drivers=enabled_drivers, **kwargs)\n\u001b[1;32m    258\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/fiona/collection.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path, mode, driver, schema, crs, encoding, layer, vsi, archive, enabled_drivers, crs_wkt, ignore_fields, ignore_geometry, **kwargs)\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWritingSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mfiona/ogrext.pyx\u001b[0m in \u001b[0;36mfiona.ogrext.Session.start\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mfiona/_shim.pyx\u001b[0m in \u001b[0;36mfiona._shim.gdal_open_vector\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mDriverError\u001b[0m: package/mapping_data/plz_ger.geojson: No such file or directory"
     ]
    }
   ],
   "source": [
    "pm10_map = Map.map_data(df = pmdata, geo_boundaries = 'package/mapping_data/plz_ger.geojson',\n",
    "                        measurement_type = \"measurement_PM10\", lat = 'lat', lon = 'lon', time_interval = \"5Min\")\n",
    "pm25_map = Map.map_data(df = pmdata, geo_boundaries = 'package/mapping_data/plz_ger.geojson',\n",
    "                        measurement_type = \"measurement_PM2.5\", lat = 'lat', lon = 'lon', time_interval = \"5Min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm10_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm25_map"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
