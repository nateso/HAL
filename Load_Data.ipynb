{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99326ae1-a001-4f57-89e3-702e4a21ea89",
   "metadata": {},
   "source": [
    "# Function for Loading the Data from a REST-API for a pd data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7803b966-76d9-47cc-aad5-c2a7dfa2e1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports:\n",
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28e0518f-7fa6-4782-b1f0-f09935bbcc4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(lat_start, lat_end, long_start, long_end, start_year, start_month, start_day, delta_hours):\n",
    "    '''Function for loading the data out of the REST-API'''\n",
    "    \n",
    "    '''INPUT:'''\n",
    "    \n",
    "    '''lat_start:                          latitude range starting point, type: byte'''\n",
    "    '''lat_end:                            latitude range ending point, type: byte'''\n",
    "    '''long_start:                         longitude range starting point, type: byte'''\n",
    "    '''long_end:                           longitude range ending point, type: byte'''\n",
    "    '''start_year, start_month, start_day: year / month / day of the measurement to start, type: byte'''\n",
    "    '''delta_hours:                        time delta to calculate time space of measurement, type: byte'''\n",
    "    \n",
    "    '''OUPUT:'''\n",
    "    \n",
    "    '''Merged data frame on P1 and P2 is outputted'''\n",
    "    \n",
    "    '''Import Data from REST_API'''\n",
    "    # Basic parameters\n",
    "    base_url='http://sensordata.gwdg.de/api/' \n",
    "    endpoint_url_P1='measurements/P1'          # P1 endpoint\n",
    "    endpoint_url_P2='measurements/P2'          # P2 endpoint\n",
    "\n",
    "    # Select geo-coordinates\n",
    "    latrange=[lat_start, lat_end]\n",
    "    longrange=[long_start, long_end]\n",
    "\n",
    "    # Select time range\n",
    "    start_date = datetime(start_year, start_month, start_day)\n",
    "    end_date = (start_date + timedelta(hours = delta_hours))\n",
    "\n",
    "    # Build the query\n",
    "    mydata = '{\"timeStart\": \"'+start_date.strftime(\"%Y-%m-%dT%H:%M:%SZ\")+'\",' + \\\n",
    "             '\"timeEnd\": \"'+end_date.strftime(\"%Y-%m-%dT%H:%M:%SZ\")+'\", \"area\":  \\\n",
    "             {\"coordinates\":['+str(latrange)+','+str(longrange)+']}}'\n",
    "\n",
    "    # Run the query\n",
    "    response_P1 = requests.post(base_url + endpoint_url_P1, data=mydata)\n",
    "    response_P2 = requests.post(base_url + endpoint_url_P2, data=mydata)\n",
    "    \n",
    "    '''Initialize data frames'''\n",
    "    j_P1 = response_P1.json()                                                                            # convert REST-API data to json at first\n",
    "    del j_P1[1]                                                                                          # delete 'sensor' string, that causes errors\n",
    "    df_P1 = pd.DataFrame(j_P1[1], columns =j_P1[0])                                                      # put all in pandas data frame\n",
    "    df_P1 = df_P1.rename(columns={\"P1\": \"measurement_PM10\"})                                             # Change column name for better overview\n",
    "    l_P1 = list(range(len(df_P1[\"sensor_id\"])))\n",
    "    for i in range(len(l_P1)):                                                                           # Adding unique measurement_id to merge P1 and P2\n",
    "        l_P1[i] = str(df_P1[\"sensor_id\"][i]) + \"_\" + str(df_P1[\"time\"][i])\n",
    "    df_P1[\"measurement_id\"] = l_P1\n",
    "    df_P1 = df_P1.reindex(columns = [\"measurement_PM10\", \"time\", \"lat\", \"lon\", \"sensor_id\", \"measurement_id\"])    # rearranging column names for better overview \n",
    "\n",
    "    \n",
    "    j_P2 = response_P2.json()\n",
    "    del j_P2[1]\n",
    "    df_P2 = pd.DataFrame(j_P2[1], columns =j_P2[0])\n",
    "    df_P2 = df_P2.rename(columns={\"P2\": \"measurement_PM2.5\"})\n",
    "    l_P2 = list(range(len(df_P2[\"sensor_id\"])))\n",
    "    for j in range(len(l_P2)):                                                                           # Adding unique measurement_id to merge P1 and P2\n",
    "        l_P2[j] = str(df_P2[\"sensor_id\"][j]) + \"_\" + str(df_P2[\"time\"][j])\n",
    "    df_P2[\"measurement_id\"] = l_P2\n",
    "    df_P2 = df_P2.reindex(columns = [\"measurement_PM2.5\", \"measurement_id\"])\n",
    "    \n",
    "    '''Initialize output'''\n",
    "    df_total = pd.merge(df_P1, df_P2, on = \"measurement_id\")                                         # merge data frame on unique measurement_id\n",
    "    df_total = df_total.reindex(columns = [\"measurement_PM10\", \"measurement_PM2.5\", \"time\", \"lat\", \"lon\", \"sensor_id\", \"measurement_id\"])\n",
    "    return df_total                                                                                  # return combined data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a520d71-1452-4f3c-8be3-69689bf8def9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>measurement_PM10</th>\n",
       "      <th>measurement_PM2.5</th>\n",
       "      <th>time</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>sensor_id</th>\n",
       "      <th>measurement_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23.10</td>\n",
       "      <td>5.93</td>\n",
       "      <td>2018-04-30T00:00:01Z</td>\n",
       "      <td>48.787</td>\n",
       "      <td>9.011</td>\n",
       "      <td>179</td>\n",
       "      <td>179_2018-04-30T00:00:01Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-04-30T00:00:01Z</td>\n",
       "      <td>48.600</td>\n",
       "      <td>9.641</td>\n",
       "      <td>3283</td>\n",
       "      <td>3283_2018-04-30T00:00:01Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-04-30T00:00:01Z</td>\n",
       "      <td>48.509</td>\n",
       "      <td>9.052</td>\n",
       "      <td>516</td>\n",
       "      <td>516_2018-04-30T00:00:01Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.43</td>\n",
       "      <td>6.60</td>\n",
       "      <td>2018-04-30T00:00:01Z</td>\n",
       "      <td>48.630</td>\n",
       "      <td>9.162</td>\n",
       "      <td>495</td>\n",
       "      <td>495_2018-04-30T00:00:01Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-04-30T00:00:01Z</td>\n",
       "      <td>48.630</td>\n",
       "      <td>9.162</td>\n",
       "      <td>498</td>\n",
       "      <td>498_2018-04-30T00:00:01Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28086</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-04-30T00:59:59Z</td>\n",
       "      <td>48.790</td>\n",
       "      <td>9.846</td>\n",
       "      <td>6172</td>\n",
       "      <td>6172_2018-04-30T00:59:59Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28087</th>\n",
       "      <td>17.57</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2018-04-30T00:59:59Z</td>\n",
       "      <td>48.487</td>\n",
       "      <td>9.231</td>\n",
       "      <td>3567</td>\n",
       "      <td>3567_2018-04-30T00:59:59Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28088</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-04-30T00:59:59Z</td>\n",
       "      <td>48.747</td>\n",
       "      <td>9.175</td>\n",
       "      <td>9915</td>\n",
       "      <td>9915_2018-04-30T00:59:59Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28089</th>\n",
       "      <td>1.20</td>\n",
       "      <td>0.90</td>\n",
       "      <td>2018-04-30T00:59:59Z</td>\n",
       "      <td>48.810</td>\n",
       "      <td>9.173</td>\n",
       "      <td>8938</td>\n",
       "      <td>8938_2018-04-30T00:59:59Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28090</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-04-30T00:59:59Z</td>\n",
       "      <td>48.761</td>\n",
       "      <td>9.152</td>\n",
       "      <td>1950</td>\n",
       "      <td>1950_2018-04-30T00:59:59Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28091 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       measurement_PM10  measurement_PM2.5                  time     lat  \\\n",
       "0                 23.10               5.93  2018-04-30T00:00:01Z  48.787   \n",
       "1                   NaN                NaN  2018-04-30T00:00:01Z  48.600   \n",
       "2                   NaN                NaN  2018-04-30T00:00:01Z  48.509   \n",
       "3                  8.43               6.60  2018-04-30T00:00:01Z  48.630   \n",
       "4                   NaN                NaN  2018-04-30T00:00:01Z  48.630   \n",
       "...                 ...                ...                   ...     ...   \n",
       "28086               NaN                NaN  2018-04-30T00:59:59Z  48.790   \n",
       "28087             17.57               2.80  2018-04-30T00:59:59Z  48.487   \n",
       "28088               NaN                NaN  2018-04-30T00:59:59Z  48.747   \n",
       "28089              1.20               0.90  2018-04-30T00:59:59Z  48.810   \n",
       "28090               NaN                NaN  2018-04-30T00:59:59Z  48.761   \n",
       "\n",
       "         lon sensor_id             measurement_id  \n",
       "0      9.011       179   179_2018-04-30T00:00:01Z  \n",
       "1      9.641      3283  3283_2018-04-30T00:00:01Z  \n",
       "2      9.052       516   516_2018-04-30T00:00:01Z  \n",
       "3      9.162       495   495_2018-04-30T00:00:01Z  \n",
       "4      9.162       498   498_2018-04-30T00:00:01Z  \n",
       "...      ...       ...                        ...  \n",
       "28086  9.846      6172  6172_2018-04-30T00:59:59Z  \n",
       "28087  9.231      3567  3567_2018-04-30T00:59:59Z  \n",
       "28088  9.175      9915  9915_2018-04-30T00:59:59Z  \n",
       "28089  9.173      8938  8938_2018-04-30T00:59:59Z  \n",
       "28090  9.152      1950  1950_2018-04-30T00:59:59Z  \n",
       "\n",
       "[28091 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example\n",
    "df = load_data(lat_start = 48, lat_end = 49, long_start = 9, long_end = 10, start_year = 2018, start_month = 4, start_day = 30, delta_hours = 1) # Stuttgart now\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fb3a729d-9bae-434e-963d-ea859b797dec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().values.any() == True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9479611d-b7ef-4ab5-8d08-af2dced18c1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2768c4-3e98-40a4-bba3-8918e75aed22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
