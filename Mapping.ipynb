{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "c1fd419f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "from folium.plugins import TimeSliderChoropleth\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import json\n",
    "from shapely.geometry import shape, Point\n",
    "import geopandas as gpd\n",
    "from branca.colormap import linear\n",
    "\n",
    "from Clean_Data import remove_outliers\n",
    "from Clean_Data import remove_missing\n",
    "from Load_Data import load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f69517e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = datetime.fromisoformat(\"2018-02-05T10:00:00\")\n",
    "df = load_data(48.7, 48.85, 9.05, 9.3, start_time, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "53fe5c27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5837 observations with missing values were removed from the data frame\n",
      "21 outlier observations were deleted\n"
     ]
    }
   ],
   "source": [
    "df = remove_missing(df)\n",
    "df = remove_outliers(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "b6332e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_data(df, geo_boundaries, lat = \"lat\", lon = \"lon\", measurement_type = \"measurement_PM10\", time_interval = \"5Min\"):\n",
    "    '''\n",
    "    Maps the PM10 and PM2.5 concentration \n",
    "    \n",
    "    INPUTS:\n",
    "    df:                  A pandas dataframe containing PM10 and Pm2.5 measurements, the location and time of the measurement\n",
    "    geo_boundaries:      A geojson file containinig the geoboundaries on which to aggregate the data\n",
    "    measurement_type:    String either measurement_PM10 or measurement_PM2.5\n",
    "    lat:                 String with the column name of latitudes in df\n",
    "    lon:                 String with the column name of longitude in df\n",
    "    time_interval:       String specifying the time interval to which to aggregate the data (e.g. 30S, 10Min, 1H, 1D)\n",
    "    \n",
    "    \n",
    "    \n",
    "    OUTPUTS:\n",
    "    index_measurement_type.html:               An HTML file with an interactive map\n",
    "    m:                                         The map\n",
    "    '''\n",
    "    \n",
    "    # Defensive programming\n",
    "    if not (isinstance(df,pd.core.frame.DataFrame)):\n",
    "        raise TypeError(\"df must be a pandas dataframe\")\n",
    "    if not \"time\" in df:\n",
    "        raise NameError(\"There is no column named time in df -- need a column named time!\")\n",
    "    if not (isinstance(geo_boundaries,str)):\n",
    "        raise TypeError(\"geo_boundaries must be a file path as string\")\n",
    "        \n",
    "    if not (isinstance(lat, str)):\n",
    "        raise TypeError(\"lat must be a string\")\n",
    "    if not lat in df:\n",
    "        raise NameError(lat+\" is not a column of df\")\n",
    "    if not (isinstance(lon,str)):\n",
    "        raise TypeError(\"lon must be a string\")\n",
    "    if not lon in df:\n",
    "        raise NameError(lon+\" is not a column of df\")\n",
    "    \n",
    "    if not (isinstance(measurement_type,str)):\n",
    "        raise TypeError(\"measurement_type must be a column name as string\")\n",
    "    if not measurement_type in df:\n",
    "        raise NameError(measurement_type+\" is not a column of df\")\n",
    "    if not isinstance(time_interval,str):\n",
    "        raise TypeError(\"time_interval must be a string\")\n",
    "    \n",
    "    # generate the PM label for the plots\n",
    "    start = measurement_type.find(\"_\")+1\n",
    "    end = len(measurement_type)\n",
    "    pm_label = measurement_type[start:end]\n",
    "    \n",
    "    # first load the geo boundaries and create a geopandas dataframe out of df\n",
    "    plz = gpd.read_file(geo_boundaries)\n",
    "    geo_df = gpd.GeoDataFrame(df,geometry = gpd.points_from_xy(df[\"lon\"], df[\"lat\"]), crs = 4326)\n",
    "    \n",
    "    # combine the geoboundaries with the geo_df (allocate the points to the correct polygons)\n",
    "    plz_pm = gpd.sjoin(plz,geo_df)\n",
    "    plz_pm['polygon_id'] = plz_pm.index\n",
    "    plz_pm = plz_pm.reset_index()\n",
    "    plz_geom = plz_pm[['polygon_id','geometry']]\n",
    "    \n",
    "    plz_pm = plz_pm[['polygon_id',measurement_type,'time']]\n",
    "    plz_pm['time'] = pd.to_datetime(plz_pm['time'])\n",
    "    \n",
    "    # aggreagte the data within each polygon by some prespecified time interval\n",
    "    # this decides on how fine grained the slider is. \n",
    "    gr_plz_pm = plz_pm.groupby([pd.Grouper(key = \"time\",freq = time_interval), 'polygon_id']).mean()\n",
    "    gr_plz_pm = gr_plz_pm.reset_index()\n",
    "    gr_plz_pm['geometry'] = plz['geometry'][gr_plz_pm['polygon_id']].reset_index()['geometry']\n",
    "    \n",
    "    # define the style dictionary which is needed for the time slider (for each polygon and \n",
    "    # each time we assign a color based on the measured PM value)\n",
    "    gr_plz_pm[\"dt_index\"] = gr_plz_pm['time'].astype(int) // 10**9  # translate time to integer values\n",
    "    cmap = linear.BuPu_09.scale(0, 50) # define the color scale\n",
    "    cmap.caption = str(pm_label+\" concentration (μg/m³)\") # define the label of the color scale (needed for plotting later)\n",
    "    \n",
    "    styledict = {}\n",
    "    for poly in pd.unique(gr_plz_pm['polygon_id']):\n",
    "    \n",
    "        meas = gr_plz_pm.loc[gr_plz_pm['polygon_id'] == poly] # only retain measurements in that polygon\n",
    "        poly = int(poly)\n",
    "        styledict[poly] = {}\n",
    "    \n",
    "        for date_time in meas['dt_index']: # for each timestamp within that polygon assign a color\n",
    "            value = float(meas[measurement_type][meas['dt_index'] == date_time]) #extract the measured value\n",
    "            styledict[poly][date_time] = {'color': cmap(value),'opacity': 0.1}  # assign a color for the polygon - time - value combination\n",
    "            # similar values will have similar colors because of the color scale cmap.\n",
    "          \n",
    "          \n",
    "    # prepare data for plotting\n",
    "    gr_plz_pm = gr_plz_pm.set_index(gr_plz_pm['polygon_id'])\n",
    "    geo_gr_plz_pm = gpd.GeoDataFrame(gr_plz_pm)\n",
    "    geo_gr_plz_pm = geo_gr_plz_pm.drop('time', axis = 1) # drop the time variable sicne else not convertibleto json file (needed for plotting)\n",
    "\n",
    "    # extract the location of all sensors\n",
    "    markers = df[df.duplicated('sensor_id') == False]\n",
    "    markers = markers[['lat','lon','sensor_id']]\n",
    "    markers = markers.reset_index()\n",
    "    \n",
    "    # Define the title, relying on html\n",
    "    time_start = min(gr_plz_pm.time).strftime(\"%d.%m.%y - %H:%M\")\n",
    "    time_end = max(gr_plz_pm.time).strftime(\"%d.%m.%y - %H:%M\")\n",
    "    loc = pm_label+\" concentrations from \"+time_start+\" to \"+time_end+\" with a time interval of \"+time_interval # define the title of the map\n",
    "    title_html = ''' <h3 align=\"center\" style=\"font-size:16px\"><b>{}</b></h3>'''.format(loc) # format the title\n",
    "    \n",
    "    center = [np.median(df[lat]), np.median(df[lon])] # define the center of the map\n",
    "    m = folium.Map(location=center, zoom_start=11) # create the base map\n",
    "    \n",
    "    g = TimeSliderChoropleth(\n",
    "        data = geo_gr_plz_pm.to_json(), # transform the geopandas dataframe to a json file\n",
    "        styledict=styledict # use the styledictionary defined earlier\n",
    "    ).add_to(m) \n",
    "    \n",
    "\n",
    "    for jj in range(markers.shape[0]): # add circle markers for all sensors\n",
    "        folium.CircleMarker(location = [markers['lat'][jj],markers['lon'][jj]],\n",
    "                            color = \"green\",radius = 1,fill = True,\n",
    "                            popup = str(\"sensor id:\"+markers['sensor_id'][jj])).add_to(m)\n",
    "   \n",
    "    m.add_child(cmap) # add the legend \n",
    "    \n",
    "    m.get_root().html.add_child(folium.Element(title_html)) # add the title\n",
    "    \n",
    "    m.save(str(\"index_\"+pm_label+\".html\")) # save the map\n",
    "    \n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "414cb0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "PM25_map = map_data(df, \"mapping_data/plz_ger.geojson\", measurement_type = \"measurement_PM2.5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "e1af7b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "PM10_map = map_data(df, \"mapping_data/plz_ger.geojson\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
